<!DOCTYPE HTML>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <link rel="stylesheet" href="style.css">
    <title>Нулевая гипотеза</title>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script type="text/javascript">
        $(document).ready(function() {
           $('a[href^="#"]').click(function () { 
             elementClick = $(this).attr("href");
             destination = $(elementClick).offset().top;
             $('html').animate( { scrollTop: destination }, 500 );
             return false;
           });
         });
        </script>
</head>

<body>
    <div class="navigation">
        <a class="navref" href="#common_theory"> Общая теория</a>
        <a class="navref" href="#correlation_theory"> Корреляционная теория случайных процессов</a>
        <a class="navref" href="#random_processes_integration"> Интегрирование случайных процессов</a>
        <a class="navref" href="#marks_random_processes"> Марковские случайные процессы</a>
        <a class="navref" href="#diffusion_processes"> Диффузионные процессы</a>
        <a class="navref" href="#forward_and_backward_kolmogorov_equation"> Прямое и обратное уравнения Колмогорова</a>
        <a class="navref" href="#common_random_processes"> Обобщенные случайные процессы</a>
        <a class="navref" href="#sources"> Источники</a>
    </div>
    
    <div class="main">
        <p><a name="common_theory" id="common_theory"></a></p>
            <p> 
                <header>
                    <h2>1.Общая теория</h2>
                </header>
                <b>Случайная величина (СВ)</b> – величина, которая в результате опыта со случайным исходом принимает то или иное значение, причем заранее, до опыта, неизвестно, какое именно.
                Множество возможных значений величины X обозначается как <img src="img/1.png">.
                В зависимости от вида множества <img src="https://chart.googleapis.com/chart?cht=tx&amp;chl=\Omega_x">, случайные величины могут быть <b>дискретными</b> и <b>непрерывными</b>.
                Случайная величина (СВ) Х называется <b>дискретной</b>, если множество <img src="https://chart.googleapis.com/chart?cht=tx&amp;chl=\Omega_x">– счетное, т.е. его элементы можно расположить в определенном порядке и пронумеровать. 
                Случайная величина Х называется <b>непрерывной (недискретной)</b>, если множество <img src="https://chart.googleapis.com/chart?cht=tx&amp;chl=\Omega_x">– несчетное. 
                <b>Законом распределения СВ Х</b> называется любая функция (правило, таблица и т.п.), устанавливающая соответствие между значениями случайной величины и вероятностями их наступления и позволяющая находить вероятности всевозможных событий p{a ≤ X < b}, ∀a, b, связанных со случайной величиной.<br>
                <b>Функцией распределения F(x)</b> СВ X называется вероятность того, что она примет значение меньшее, чем аргумент функции x: F(x) = p{X < x}.<br>
                <b>Функция распределения любой ДСВ</b> есть разрывная ступенчатая функция, скачки которой происходят в точках, соответствующих возможным значениям случайной величины, и равны вероятностям этих значений:<br><br>
                <img src="img/2.png"><br><br>
                Случайная величина Х называется <b>непрерывной</b>, если ее функция распределения F(x) – непрерывная и дифференцируемая функция для всех значений аргумента.<br><br>
                <b>Плотностью распределения</b> (плотностью вероятности) f(x) НСВ X называется производная ее функции распределения:<br><br>
                <img src="img/3.png"><br>
                <header>
                    <h3>Числовые характеристики случайной величины</h3>
                </header>
                Различают характеристики положения (математическое ожидание, медиана, мода) и вариации (размах, абсолютное отклонение, средне квадратическое отклонение)
                <b>Математическое ожидание</b> характеризует среднее значение СВ и определяется по формулам:<br><br>
                <img src="img/4.png"><br><br>
                <b>Начальный момент k-го порядка</b> СВ X есть математическое ожидание k-й степени этой случайной величины:<br><br>
                <img src="img/5.png"><br><br>
                <b>Дисперсия</b> СВ характеризует степень рассеивания (разброса) значений случайной величины относительно ее математического ожидания и определяется по формулам:<br><br>
                <img src="img/6.png"><br><br>
                <b>Среднее квадратическое отклонение</b> СВ X характеризует ширину диапазона значений X и равно:<br><br>
                <img src="img/7.png"><br><br>
                <b>Мода</b> СВ равна ее наиболее вероятному значению, т.е. то значение, для которого вероятность Pi (для дискретной случайной величины) или f(x) (для непрерывных случайной величины) достигает максимума:<br><br>
                <img src="img/8.png"><br><br>
                Медиана СВ X равна такому ее значению, для которого выполняется условие p{X < Me} = p{X ≥ Me}. Медиана, как правило, существует только для непрерывных случайных величин. Значение Me может быть определено как решение одного из следующих уравнений:<br><br>
                <img src="img/9.png"><br>
                <header>
                    <h3>Двумерные СВ</h3>
                </header>
                <b>Двухмерная СВ</b> – совокупность двух одномерных случайных величин, которые принимают значения в результате проведения одного и того же опыта.<br><br>
                Двухмерную случайную величину (Х, Y) геометрически можно представить как случайную точку (Х, У) на плоскости х0у либо как случайный вектор, направленный из начала координат в точку (Х, У): <br><br>
                <img src="img/10.png"><br><br>
                <b>Двухмерный закон распределения вероятностей</b> – функция, таблица, правило, позволяющие вычислить вероятности любых случайных событий, связанных двухмерной случайной величиной (Х, Y):<br><br>
                <img src="img/11.png"><br><br>
                <b>Двухмерная функция распределения</b> двухмерной случайной величины (Х, Y) равна вероятности совместного выполнения двух событий {Х < х} и {Y < у}:<br><br>
                <img src="img/12.png"><br><br>
                <b>Двухмерная плотность распределения f(х, у)</b> характеризует плотность вероятности в окрестности точки с координатами (х, у) и равна второй смешанной производной функция распределения:<br><br>
                <img src="img/13.png"><br><br>
                Смешанный начальный момент порядка k + s равен математическому ожиданию произведения X^k и Y^s:<br><br>
                <img src="img/14.png"><br><br>
                <b>Корреляционный момент</b> характеризует степень тесноты линейной зависимости величин X и Y и рассеивание их значений относительно точки (m_x, m_y):<br><br>
                <img src="img/15.png"><br><br>
                Если K < 0, то между величинами X и Y существует <b>отрицательная корреляционная зависимость</b>, т.е. чем больше значение одной величины, тем более вероятны меньшие значение у другой. <br>
                Если K > 0, то между величинами X и Y существует <b>положительная корреляционная зависимость</b>, т.е. чем больше значение одной величины, тем более вероятны большие значения у другой. <br>
                Если K  = 0, то величины X и Y называются <b>корреляционно независимыми</b> или <b>некоррелированными</b>, т.е. между ними отсутствует зависимость линейного характера. <br>
                Если K  ≠ 0, то величины X и Y называются <b>коррелированными</b>. <br>
                Из <u>коррелированности</u> двух СВ следует их <u>зависимость</u>, но из зависимости еще <u>НЕ</u> вытекает их коррелированность, так как зависимость может иметь и нелинейный характер. <br>
                Из <u>независимости</u> СВ обязательно следует их <u>некоррелированность</u>, но из некоррелированности <u>НЕ</u> всегда следует независимость этих величин.<br>
                <b>Коэффициент корреляции</b> характеризует степень линейной зависимости величин и равен:<br><br>
                <img src="img/16.png"><br><br>
                Корреляционный момент нормируется для того, чтобы получить характеристику только степени тесноты линейной зависимости (ковариация зависит от дисперсии СВ, т.е. их рассеивания от значений точки (m_x,m_y)).<br>
            </p>
        <p><a name="correlation_theory" id="correlation_theory"></a></p> 
            <p>
                <header>
                    <h2>2. Корреляционная теория случайных процессов</h2>
                </header>
                <b>Случайная функция (СФ) X(t)</b> – функция неслучайного аргумента t, которая при каждом фиксированном значении аргумента является случайной величиной.<br>
                <b>Сечение СФ X(t)</b> – случайная величина, соответствующая фиксированному значению аргумента случайной функции.<br>
                <b>Реализация СФ X(t)</b> – неслучайная функция аргумента t, которая может оказаться равной случайной функции в результате испытания.<br>
                <b>Корреляционная функция СФ X(t)</b> – неслучайная функция двух независимых аргументов t1  и t2, значение которой при каждой паре фиксированных значений аргументов равно корреляционному моменту сечений, соответствующих этим же фиксированным значениям аргументов:<br>
                <img src="img/17.png"><br><br>
                При равных между собой значениях аргументов t1 = t2 = t корреляционной функции СФ равна дисперсии этой функции:<br><br>
                <img src="img/18.png"><br><br>
                Корреляционная функция характеризует степень зависимости между сечениями СФ, относящимся к различным t. Свойства корреляционной функции:<br><br>
                <img src="img/19.png"><br><br>
                <b>Взаимная корреляционная функция (корреляционная функция связи)</b> двух СФ X(t) и Y(t) – неслучайная функция двух независимых аргументов t1 и t2, значение которой при каждой паре фиксированных значений аргументов равно корреляционному моменту сечений обеих функций, соответствующих этим же фиксированным значениям аргументов:<br><br>
                <img src="img/20.png"><br><br>
                <b>Коррелированными</b> называют две СФ, если их взаимная корреляционная функция не равна тождественно нулю.<br>
                <b>Некоррелированными</b> называют две СФ, взаимная корреляционная функция которых тождественно равна 0.<br><br>
                Свойства взаимной корреляционной функции:<br><br>
                <img src="img/21.png"><br><br>
            </p>
        <p><a name="random_processes_integration" id="random_processes_integration"></a></p> 
            <p>
                <header>
                    <h2>3. Интегрирование случайных процессов</h2>
                </header>
                Рассмотрим интеграл Дюамеля:<br><br>
                <img src="img/22.png"><br><br>
                Где g(t,τ) – некоторая функция двух переменных (весовая функция).<br>
                X(τ) – случайная функция. <br>
                t - t0 = T – область интегрирования.<br><br>
                <img src="img/23.png"><br><br>
                <img src="img/24.png"><br><br>
                <img src="img/25.png"><br><br>
                <img src="img/26.png"><br><br>
                <img src="img/27.png"><br><br>
                <img src="img/28.png"><br><br>
                СФ X(τ) будем называть интегрируемой по области Т с весом g(t,τ), если существует СФ Y(t), называемая интегралом такая, что <br><br>
                <img src="img/29.png"><br><br>
                Интеграл Y(t) – предел в среднем квадратическом от интегральной суммы:<br><br>
                <img src="img/30.png"><br><br>

            </p>  
        <p><a name="marks_random_processes" id="marks_random_processes"></a></p> 
            <p>
                <header>
                    <h2>4. Марковские случайные процессы</h2>
                </header>
                <b>Марковский случайный процесс (процесс без последействия)</b> – случайный процесс ξ(t), состояние в каждый момент времени которого зависит только от состояния в предшествующий момент и не зависит от прежних состояний. <b>Марковская цепь</b> – последовательность сечений марковского случайного процесса. <br>
                ξ(t_i) – сечения процесса. Множество E = {ξ(t_0 ),…,ξ(t_n )}, т.е. множество всех вохможных состояний системы, называется <b>фазовым пространством</b>.<br>
                Сечения процесса - состояния системы.<br> 
                <i>Одно из свойств, сильно упрощающее исследование случайного процесса — это «марковское свойство». Если объяснять очень неформальным языком, то марковское свойство сообщает нам, что если мы знаем значение, полученное каким-то случайным процессом в заданный момент времени, то не получим никакой дополнительной информации о будущем поведении процесса, собирая другие сведения о его прошлом. Более математическим языком: в любой момент времени условное распределение будущих состояний процесса с заданными текущим и прошлыми состояниями зависит только от текущего состояния, но не от прошлых состояний (свойство отсутствия памяти). Случайный процесс с марковским свойством называется марковским процессом.</i><br>
                Условная функция распределения<br><br>
                <img src="img/31.png"><br><br>
                называется <b>марковской переходной функцией</b>.<br>
                Условная плотность распределения<br><br>
                <img src="img/32.png"><br><br>
                называется <b>переходной вероятностью</b> (вероятность перехода системы из состояния x_n в состояние x_(n+1)  на интервале времени [t_n, t_(n+1)]).<br>
                Случайный процесс ξ(t) является марковским, если его условная функция распределения не зависит от значений процесса в прошлые моменты времени t_1, …, t_(n-1), а определяется лишь значением в настоящий момент времени t_n, то есть выполняется равенство:<br><br>
                <img src="img/33.png"><br><br>
                (Это неравенство интерпретируют как указание на то, что для марковского процесса будущее не зависит от прошлого при известном настоящем)<br>
                Вероятности переходов удовлетворяют двум основным соотношениям:<br>
                1. Условию нормировки (справедливо для всех стохастических систем):<br><br>
                <img src="img/34.png"><br><br>
                (сумма вероятностей в одной строке матрицы равна единице)<br>
                2. Уравнению Чепмена - Колмогорова. Это уравнение является определяющим в методах исследования марковских процессов и имеет весьма широкий спектр представлений:<br><br>
                <img src="img/35.png"><br><br>
                Все марковские процессы можно разделить на классы в зависимости от структуры множества X - значений случайного процесса ξ(t) и интервала времени наблюдения Т. Если множество X - дискретное, то есть конечное или счётное, то процесс ξ(t) называется <u>цепью Маркова</u>. При этом, если Т — дискретное, то процесс называется <u>цепью Маркова с дискретным временем</u>, а если Т - непрерывное (то есть система может менять свои состояния в произвольные моменты времени), то процесс называется <u>цепью Маркова с непрерывным временем</u>. Если оба множества X и Т непрерывные, то процесс называется <u>непрерывным марковским процессом</u>. <br>
                <header>
                    <h3>Цепи Маркова с дискретным временем</h3>
                </header>  
                Пусть случайный процесс ξ(t) изменения во времени состояний некоторой системы принимает целочисленные значения i —1,2,... из множества X конечного или счётного, то есть ξ(t)=i,  ξ(t') = j. Переходы из одного состояния в другое происходят через равные промежутки времени |t' – t| = 1, которые будем называть шагом.<br>
                Условные вероятности вида: <br><br>
                <img src="img/36.png"><br><br>
                называются <b>вероятностями перехода</b>, или <b>переходными вероятностями</b>.<br>
                Они образуют матрицу вероятностей переходов (Марковская матрица, стохастическая матрица). В большинстве случаев рассматривают однородные цепи Маркова, где вероятности переходов p_ij(t) не зависят от t:<br><br>
                <img src="img/37.png"><br><br>
                Для однородных цепей матрица переходов имеет вид:<br><br>
                <img src="img/38.png"><br><br>
                Условие нормировки для такой матрицы:<br><br>
                <img src="img/39.png"><br><br>
                (сумма элементов одной строки всегда равна единице, так как система обязательно окажется в каком-то из своих состояний)<br>
                Граф вероятностей переходов (граф Маркова) – еще один способ изобразить марковскую цепь. Например, для матрицы<br><br>
                <img src="img/40.png"><br><br>
                граф имеет вид:<br><br>
                <img src="img/41.png"><br><br>
                Уравнение Чепмена-Колмогорова (вероятность перехода из состояния i в состояние j за m шагов) для дискретной цепи записывается как <br><br>
                <img src="img/42.png"><br><br>
                Рекуррентная формула (для того, чтобы попасть в состояние j, нужно сначала за m-1 шагов попасть в состояние k, а затем перейти в j). <br>
                
                <header>
                    <h3>Классификация состояний цепей Маркова с дискретным временем</h3>
                </header>  
                •	Cостояние i называется <u>несущественным</u>, если существует такое состояние j, в которое система может перейти за конечное число шагов n, но не может вернуться в i-е состояние ни за какое число шагов, то есть<br>
                <img src="img/43.png"><br><br>
                Все остальные состояния называются <u>существенными</u>.
                •	Состояния i и j называются <u>сообщающимися</u> (i ↔ j), если существуют n и m такие, что<br><br>
                <img src="img/44.png"><br><br>
                •	Все существенные состояния можно разделить на классы, которые состоят из сообщающихся состояний и ни из одного состояния данного класса нельзя перейти в состояние другого класса. Такие классы состояний называются неразложимыми (замкнутыми).<br><br>
                •	Определим вероятность первого возвращения в состояние i на n-м шаге:<br><br>
                <img src="img/45.png"><br><br>
                Тогда вероятность<br><br>
                <img src="img/46.png"><br><br>
                можно рассматривать как вероятность того, что система, выйдя из состояния i, хоть раз вернется в него.
                Если f_i=1, то состояние называется <u>возвратным</u>, если f_i < 1 – <u>невозвратным</u>. 
                <b>Теорема солидарности.</b> Если имеются два сообщающихся состояния и одно из них – возвратное, то и второе тоже возвратное.

                <header>
                    <h3>Цепи Маркова с непрерывным временем</h3>
                </header> 
                Рассмотрим ещё один класс марковских процессов, который характеризуется тем, что не только время, но и множество состояний этих процессов непрерывно. Такие процессы образуют класс непрерывных марковских процессов, являющихся достаточно адекватными моделями многих реальных процессов. <br>
                Случайный процесс ξ(t) называется <b>непрерывным марковским</b>, если для любых моментов времени s' < s < t ꞓ T и любых действительных у выполнено равенство<br>
                Р{ ξ(t) < y| ξ(s) = x, ξ(s')  = z} = P{ ξ(t) < y| ξ(s) = x} = F(s,x;t,y).<br>
                Условная функция распределения F(s,x;t,y) называется <b>марковской переходной функцией</b>. 
                Задание этой функции и начального распределения вероятностей состояний полностью определяет марковский процесс. Если существует производная <br><br>
                <img src="img/47.png"><br><br>
                которая называется плотностью вероятностей переходов, то для марковской переходной функции можно записать<br><br>
                <img src="img/48.png"><br><br>
    
            </p>  
        <p><a name="diffusion_processes" id="diffusion_processes"></a></p> 
            <p>
                <header>
                    <h2>5. Диффузионные процессы</h2>
                </header>
                Непрерывный марковский процесс называется <b>диффузионным</b>, если его марковская переходная функция удовлетворяет следующим условиям:<br>
                1. Для любого ε > 0 и любых х равномерно по s < t выполняется предельное равенство<br><br>
                <img src="img/49.png"><br><br>
                Это условие требует, чтобы вероятность того, что |ξ(t) - ξ(s)| > ε, была бы величиной бесконечно малой более высокого порядка малости, чем |t – s| при t → s. <br>
                2. Существуют функции a(s,x) и b(s,x) такие, что<br><br>
                <img src="img/50.png"><br><br>
                Здесь функция a(s,x)  называется <b>коэффициентом переноса</b>, а функция b(s,x) — <b>коэффициентом диффузии</b>. <br>
                3. Для любых k > 2<br><br>
                <img src="img/51.png"><br><br>
                Для однородных диффузионных процессов коэффициенты переноса и диффузии не зависят от времени s, то есть имеют вид a(s, х) = a(x), b(s, х) = b(х).<br>

            </p>
        <p><a name="forward_and_backward_kolmogorov_equation" id="forward_and_backward_kolmogorov_equation"></a></p> 
            <p>
                <header>
                    <h2>6. Прямое и обратное уравнения Колмогорова</h2>
                </header>
                Формально дифференцируя уравнение Колмогорова—Чепмена по s при s = 0 получаем <b>прямое уравнение Колмогорова</b>:<br><br>
                <img src="img/52.png"><br><br>
                где<br><br>
                <img src="img/53.png"><br><br>
                Формально дифференцируя уравнение Колмогорова — Чепмена по t при t = 0 получаем <b>обратное уравнение Колмогорова</b> dP(t)dt=QP(t). Необходимо подчеркнуть, что для бесконечномерных пространств оператор Q уже не обязательно непрерывен, и может быть определен не всюду, например, быть дифференциальным оператором в пространстве распределений.<br>
            </p>              
        <p><a name="common_random_processes" id="common_random_processes"></a></p> 
            <p>
                <header>
                    <h2>7. Обобщенные случайные процессы</h2>
                </header>
                Рассмотрим пространство К бесконечно дифференцируемых финитных функций φ(t). Мы будем говорить, что задан <b>случайный функционал</b> Ф в этом пространстве, если каждому элементу пространства К сопоставлена случайная величина Ф(φ).<br>
                <i>(финитные = конечные)</i><br>
                Случайный функционал Ф(φ) называется <b>линейным</b>, если для любых элементов φ и ψ из пространства К и любых чисел и α и β выполняется равенство:<br><br>
                <img src="img/54.png"><br><br>
                Cлучайный функционал Ф(φ) называется <b>непрерывным</b>, если из того, что функции <img src="img/55.png"> сходятся к <img src="img/56.png"> в пространстве К (1 <= j <= n), вытекает равенство:<br><br>
                <img src="img/57.png"><br><br>
                Подобно тому как <u>непрерывный линейный функционал в пространстве К</u> называют <u>обобщенной функцией</u>, <u>непрерывный линейный случайный функционал в пространстве К</u> мы будем называть <u>обобщенной случайной функцией</u>. В случае, когда пространство К состоит из функций одного переменного, соответствующую случайную функцию называют <b>обобщенным случайным процессом</b>.<br>
                Приведем примеры обобщенных случайных процессов. Сопоставим линейно независимым функциям φ_1(х), ... , φ_n(х) из пространства К случайную величину (Ф(φ1), .... Ф(φn)) с распределением вероятностей<br><br>
                <img src="img/58.png"><br><br>
                где Λφ  - матрица, обратная матрице ||b_jk||, состоящей из чисел<br><br>
                <img src="img/59.png"><br><br>
                Обобщенный случайный процесс, задаваемый таким распределением вероятностей, называется <u>единичным</u>. Этот процесс можно истолковать как результат измерения некоторым прибором скорости частицы, совершающей одномерное броуновское движение и не имеющей инерции. Единичный случайный процесс не является обычным случайным процессом, поскольку скорость броуновской частицы в каждый данный момент времени не имеет распределения вероятностей.<br>
                Операции над обобщенными случайными процессами определяются аналогично тому, как это делается для обобщенных функций. Например, под линейной комбинацией αΦ1 + βΦ2 обобщенных случайных процессов Ф1 и Φ2, понимают обобщенный случайный процесс Ф, сопоставляющий каждой функции φ(t) из пространства К случайную величину αΦ1(φ) + βΦ2(φ). Таким образом, множество всех обобщенных случайных процессов образует линейное пространство.<br>
                Обычно операции над обобщенными случайными процессами определяются при помощи соответствующих операций над основными функциями φ(t). Так, под произведением бесконечно дифференцируемой функции f(t) на обобщенный случайный процесс Ф мы понимаем процесс, при котором функции φ(t) из пространства К соответствует случайная величина Ф(fφ). Точно так же под производной Ф' обобщенного случайного процесса Ф мы понимаем процесс, при котором функции φ(t) соответствует случайная величина — Ф(φ').<br>
                Заметим, что, в то время как производная обычного случайного процесса может уже не являться случайным процессом того же типа, производная обобщенного случайного процесса всегда существует и является обобщенным случайным процессом. В частности, хотя производная винеровского случайного процесса не является обычным случайным процессом, она является обобщенным случайным процессом.<br>
        </p> 
        <p><a name="sources" id="sources"></a>
            <header>
                <h2>8. Источники</h2>
            </header>
            •	Вентцель А.Д Курс теории случайных процессов/А.Д. Вентцель. - М.: Наука, гл. ред. физ-мат литературы, 1975. - 320 с.<br>
            •	Назаров А.А. Теория вероятностей и случайных процессов: учебное пособие/Назаров А.А., Терпугов А.Ф. - 2-е изд., испр. - Томск : Изд-во НТЛ, 2010.-204 с.<br>
            •	Вентцель Е.С. Теория вероятностей: Учеб. для вузов/Е.С. Вентцель. - 10-е изд., стер. - М.: Высш. шк., 2006. - 575 с.<br>
            •	Kenneth B. An introduction to probability and random processes/Kenneth Backlawski, Gian-Carlo Rota - 1979. - 467 c.<br>
            <br>
            Также предлагаем вашему вниманию курс лекций по случайным процессам ФИВТ МФТИ.<br><br>
            <div class="videos">
                <iframe width="560" height="315" src="https://www.youtube.com/embed/ry-HBJpsWNY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br><br>                   
                <iframe width="560" height="315" src="https://www.youtube.com/embed/BAO7pCcWolc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br><br>
                <iframe width="560" height="315" src="https://www.youtube.com/embed/UTiJvQkWMKs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br><br>
                <iframe width="560" height="315" src="https://www.youtube.com/embed/_vC0h5sWxRo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </div>
        </p>
    </div>
</body>
</html>
